{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data # 和normal不同的地方\n",
    "from d2l import torch as d2l\n",
    "\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = torch.tensor(4.2)\n",
    "features, labels = d2l.synthetic_data(true_w, true_b, 1000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-1.0662, -1.7531],\n",
      "        [-0.9789,  0.5528],\n",
      "        [-0.1894,  0.2043],\n",
      "        [ 0.1258,  0.8813],\n",
      "        [ 1.3177, -0.8540],\n",
      "        [ 1.3989, -0.2982],\n",
      "        [-2.2129,  0.4788],\n",
      "        [-0.9084, -1.8034],\n",
      "        [ 0.8475,  0.8483],\n",
      "        [-0.6528, -0.2739]]), tensor([[ 8.0346],\n",
      "        [ 0.3636],\n",
      "        [ 3.1248],\n",
      "        [ 1.4581],\n",
      "        [ 9.7323],\n",
      "        [ 8.0040],\n",
      "        [-1.8546],\n",
      "        [ 8.4904],\n",
      "        [ 3.0057],\n",
      "        [ 3.8348]])]\n"
     ]
    }
   ],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    # 构造一个pytorch迭代器\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train, generator=torch.Generator(device='cuda')) # 新版pytorch记得在dataloader后指定generator的device\n",
    "\n",
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)\n",
    "\n",
    "print(next(iter(data_iter)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "'''\n",
    "nn.Linear(m, n)定义了一个线性回归模型，第一层有m个unit，第二层有n个unit\n",
    "nn.Sequential里面的参数是把一堆model按顺序叠在一起\n",
    "'''\n",
    "net = nn.Sequential(nn.Linear(2, 1))\n",
    "net[0].weight.data.normal_(0, 0.01) # 为线性模型的weight和bias初始化参数\n",
    "net[0].bias.data.fill_(0)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch @1 loss : 0.00020432057499419898\n",
      "epoch @2 loss : 0.00010260935960104689\n",
      "epoch @3 loss : 0.00010328905773349106\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 3\n",
    "for epoch in range(num_epoch):\n",
    "    for X, y in data_iter:\n",
    "        l = loss(net(X),  y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    l = loss(net(features), labels)\n",
    "    print('epoch @{} loss : {}'.format(epoch + 1, float(l)))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
